{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "from itertools import combinations\n",
        "\n",
        "# Define the fixed list of items (ensuring deterministic behavior)\n",
        "items = [\"Milk\", \"Bread\", \"Eggs\", \"Diapers\", \"Soap\", \"Shampoo\", \"Towel\", \"Juice\", \"Cereal\", \"Cheese\"]\n",
        "\n",
        "# Seed the random number generator for repeatability\n",
        "random.seed(2020)\n",
        "\n",
        "# Save the items list into a file\n",
        "items_file = \"items.csv\"\n",
        "with open(items_file, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    for item in items:\n",
        "        writer.writerow([item])\n",
        "\n",
        "# Function to read the items list from a file\n",
        "def read_items(file_path):\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return [line.strip() for line in f if line.strip()]\n",
        "\n",
        "# Function to generate a random number of items per transaction (between 3 and 8)\n",
        "def get_random_count():\n",
        "    return random.randint(3, 8)\n",
        "\n",
        "# Function to generate a set of transactions\n",
        "def generate_transactions(item_list, num_transactions=20):\n",
        "    transactions = []\n",
        "    for _ in range(num_transactions):\n",
        "        num_items = get_random_count()\n",
        "        transaction = random.sample(item_list, num_items)\n",
        "        transactions.append(sorted(transaction))  # Sorting to ensure deterministic order\n",
        "    return transactions\n",
        "\n",
        "# Function to save transactions into a CSV file\n",
        "def save_transactions(transactions, file_path):\n",
        "    with open(file_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        for transaction in transactions:\n",
        "            writer.writerow(transaction)\n",
        "\n",
        "# Load the items from the saved file\n",
        "loaded_items = read_items(items_file)\n",
        "\n",
        "# Generate and save 5 transaction datasets\n",
        "for i in range(1, 6):\n",
        "    transactions = generate_transactions(loaded_items)\n",
        "    save_transactions(transactions, f\"data{i}.csv\")\n",
        "\n",
        "print(\"Data generation complete. Files generated: items.csv, data1.csv, data2.csv, data3.csv, data4.csv, data5.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47MV4A8hF4LY",
        "outputId": "f8126f1d-745c-4fcd-de05-1674e2de0b43"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data generation complete. Files generated: items.csv, data1.csv, data2.csv, data3.csv, data4.csv, data5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import itertools\n",
        "import time\n",
        "from apriori_python import apriori\n",
        "\n",
        "# Function to read a CSV file and return list of transactions (each transaction is a list)\n",
        "def read_csv(filename):\n",
        "    data = []\n",
        "    try:\n",
        "        with open(filename, \"r\") as f:\n",
        "            reader = csv.reader(f)\n",
        "            for row in reader:\n",
        "                if row:\n",
        "                    data.append([item.strip() for item in row if item.strip() != \"\"])\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {filename}: {e}\")\n",
        "    return data\n",
        "\n",
        "# Calculate how many transactions contain the itemset\n",
        "def support_count(itemset, transactions):\n",
        "    return sum(1 for trans in transactions if set(itemset).issubset(set(trans)))\n",
        "\n",
        "# Generate association rules from frequent itemsets using a simple approach\n",
        "def generate_rules(frequent_itemsets, transactions, min_confidence):\n",
        "    rules = []\n",
        "    for itemset in frequent_itemsets:\n",
        "        if len(itemset) < 2:\n",
        "            continue\n",
        "        # Try every possible non-empty subset of itemset as antecedent\n",
        "        for i in range(1, len(itemset)):\n",
        "            for antecedent in itertools.combinations(itemset, i):\n",
        "                antecedent = list(antecedent)\n",
        "                consequent = list(set(itemset) - set(antecedent))\n",
        "                if not antecedent:\n",
        "                    continue\n",
        "                count_antecedent = support_count(antecedent, transactions)\n",
        "                count_itemset = support_count(itemset, transactions)\n",
        "                if count_antecedent == 0:\n",
        "                    continue\n",
        "                confidence = count_itemset / count_antecedent\n",
        "                if confidence >= min_confidence:\n",
        "                    rules.append({\n",
        "                        \"full_itemset\": itemset,\n",
        "                        \"antecedent\": antecedent,\n",
        "                        \"consequent\": consequent,\n",
        "                        \"support\": round(count_itemset/len(transactions), 4),\n",
        "                        \"confidence\": round(confidence, 4)\n",
        "                    })\n",
        "    return rules\n",
        "\n",
        "# Brute-force method: generate all possible item combinations and filter by support\n",
        "def brute_force(transactions, items, min_support, min_confidence):\n",
        "    n = len(transactions)\n",
        "    min_count = min_support * n\n",
        "    all_frequent = []\n",
        "    start_time = time.perf_counter()\n",
        "    k = 1\n",
        "    while True:\n",
        "        combos = list(itertools.combinations(items, k))\n",
        "        freq = []\n",
        "        for combo in combos:\n",
        "            count = support_count(combo, transactions)\n",
        "            if count >= min_count:\n",
        "                freq.append(combo)\n",
        "        if not freq:\n",
        "            break\n",
        "        all_frequent.extend(freq)\n",
        "        k += 1\n",
        "    rules = generate_rules(all_frequent, transactions, min_confidence)\n",
        "    exec_time = time.perf_counter() - start_time\n",
        "    return all_frequent, rules, exec_time\n",
        "\n",
        "# Run the Apriori algorithm from the package\n",
        "def run_apriori_algo(transactions, min_support, min_confidence):\n",
        "    start_time = time.perf_counter()\n",
        "    freq_itemsets, assoc_rules = apriori(transactions, minSup=min_support, minConf=min_confidence)\n",
        "    flat_freq = []\n",
        "    for size, itemset_list in freq_itemsets.items():\n",
        "        for itemset in itemset_list:\n",
        "            flat_freq.append(tuple(itemset))\n",
        "    rules = []\n",
        "    for rule in assoc_rules:\n",
        "        antecedent = tuple(rule[0])\n",
        "        consequent = tuple(rule[1])\n",
        "        full_itemset = tuple(set(antecedent) | set(consequent))\n",
        "        count_full = support_count(full_itemset, transactions)\n",
        "        rules.append({\n",
        "            \"full_itemset\": full_itemset,\n",
        "            \"antecedent\": antecedent,\n",
        "            \"consequent\": consequent,\n",
        "            \"support\": round(count_full/len(transactions), 4),\n",
        "            \"confidence\": round(rule[2], 4)\n",
        "        })\n",
        "    exec_time = time.perf_counter() - start_time\n",
        "    return flat_freq, rules, exec_time"
      ],
      "metadata": {
        "id": "HDgROJmgKVVF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # Prompt user for input\n",
        "    ds_num = input(\"Enter dataset number (1-5): \").strip()\n",
        "    if ds_num not in ['1', '2', '3', '4', '5']:\n",
        "        print(\"Invalid dataset selection. Exiting.\")\n",
        "        return\n",
        "    dataset_file = f\"data{ds_num}.csv\"\n",
        "    try:\n",
        "        transactions = read_csv(dataset_file)\n",
        "        if not transactions:\n",
        "            print(\"No transactions found in the selected dataset.\")\n",
        "            return\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    # Read the items list from items.csv\n",
        "    try:\n",
        "        items_data = read_csv(\"items.csv\")\n",
        "        # Each row in items.csv has one item; flatten the list\n",
        "        items = [row[0] for row in items_data if row]\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading items: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        min_support = float(input(\"Enter minimum support (e.g., 0.3): \").strip())\n",
        "        min_confidence = float(input(\"Enter minimum confidence (e.g., 0.6): \").strip())\n",
        "    except Exception as e:\n",
        "        print(\"Invalid support or confidence value. Exiting.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nRunning Apriori algorithm (Python package)...\")\n",
        "    apriori_freq, apriori_rules, time_apriori = run_apriori_algo(transactions, min_support, min_confidence)\n",
        "\n",
        "    print(\"\\nRunning Brute-force algorithm...\")\n",
        "    brute_freq, brute_rules, time_brute = brute_force(transactions, items, min_support, min_confidence)\n",
        "\n",
        "    # Output results\n",
        "    print(\"\\n=== RESULTS ===\")\n",
        "    print(f\"Dataset: {dataset_file}\")\n",
        "    print(f\"Minimum Support: {min_support} | Minimum Confidence: {min_confidence}\\n\")\n",
        "\n",
        "    print(\"--- APRIORI RESULTS ---\")\n",
        "    print(f\"Total Frequent Itemsets Found: {len(apriori_freq)}\")\n",
        "    print(\"Frequent Itemsets:\")\n",
        "    for itemset in apriori_freq[:10]:  # Display only first 10 for brevity\n",
        "        count = support_count(itemset, transactions)\n",
        "        support_val = round(count/len(transactions), 4)\n",
        "        print(f\"{itemset} - Count: {count}, Support: {support_val}\")\n",
        "    if len(apriori_freq) > 10:\n",
        "        print(\"... (more frequent itemsets found)\")\n",
        "\n",
        "    print(\"\\nTotal Association Rules Generated: \", len(apriori_rules))\n",
        "    print(\"Sample Rules:\")\n",
        "    if apriori_rules:\n",
        "        for rule in apriori_rules[:5]:  # Display first 5 rules\n",
        "            print(f\"{rule['antecedent']} => {rule['consequent']}, Support: {rule['support']}, Confidence: {rule['confidence']}\")\n",
        "        if len(apriori_rules) > 5:\n",
        "            print(\"... (more rules found)\")\n",
        "    else:\n",
        "        print(\"No association rules generated by Apriori.\")\n",
        "\n",
        "    print(\"\\n--- BRUTE-FORCE RESULTS ---\")\n",
        "    print(f\"Total Frequent Itemsets Found: {len(brute_freq)}\")\n",
        "    print(\"Frequent Itemsets:\")\n",
        "    for itemset in brute_freq[:10]:  # Display only first 10 for brevity\n",
        "        count = support_count(itemset, transactions)\n",
        "        support_val = round(count/len(transactions), 4)\n",
        "        print(f\"{itemset} - Count: {count}, Support: {support_val}\")\n",
        "    if len(brute_freq) > 10:\n",
        "        print(\"... (more frequent itemsets found)\")\n",
        "\n",
        "    print(\"\\nTotal Association Rules Generated: \", len(brute_rules))\n",
        "    print(\"Sample Rules:\")\n",
        "    if brute_rules:\n",
        "        for rule in brute_rules[:5]:  # Display first 5 rules\n",
        "            print(f\"{rule['antecedent']} => {rule['consequent']}, Support: {rule['support']}, Confidence: {rule['confidence']}\")\n",
        "        if len(brute_rules) > 5:\n",
        "            print(\"... (more rules found)\")\n",
        "    else:\n",
        "        print(\"No association rules generated by brute-force.\")\n",
        "\n",
        "    print(\"\\n--- EXECUTION TIME COMPARISON ---\")\n",
        "    print(f\"Apriori execution time: {time_apriori:.4f} seconds\")\n",
        "    print(f\"Brute-force execution time: {time_brute:.4f} seconds\")\n",
        "\n",
        "    if time_apriori < time_brute:\n",
        "        print(\"Apriori algorithm is faster.\")\n",
        "    else:\n",
        "        print(\"Brute-force algorithm is faster.\")\n",
        "\n",
        "    print(\"\\n--- FINAL COMPARISON SUMMARY ---\")\n",
        "    print(f\"Total Frequent Itemsets: Apriori = {len(apriori_freq)}, Brute-force = {len(brute_freq)}\")\n",
        "    print(f\"Total Association Rules: Apriori = {len(apriori_rules)}, Brute-force = {len(brute_rules)}\")\n",
        "    print(f\"Execution Time: Apriori = {time_apriori:.4f}s, Brute-force = {time_brute:.4f}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ipBnyb-PPTz",
        "outputId": "b6f8fdd2-4a72-49a7-baa1-ae5af05b3f3f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter dataset number (1-5): 1\n",
            "Enter minimum support (e.g., 0.3): 0.3\n",
            "Enter minimum confidence (e.g., 0.6): 0.6\n",
            "\n",
            "Running Apriori algorithm (Python package)...\n",
            "\n",
            "Running Brute-force algorithm...\n",
            "\n",
            "=== RESULTS ===\n",
            "Dataset: data1.csv\n",
            "Minimum Support: 0.3 | Minimum Confidence: 0.6\n",
            "\n",
            "--- APRIORI RESULTS ---\n",
            "Total Frequent Itemsets Found: 66\n",
            "Frequent Itemsets:\n",
            "('Soap',) - Count: 8, Support: 0.4\n",
            "('Towel',) - Count: 11, Support: 0.55\n",
            "('Eggs',) - Count: 12, Support: 0.6\n",
            "('Cereal',) - Count: 15, Support: 0.75\n",
            "('Juice',) - Count: 14, Support: 0.7\n",
            "('Diapers',) - Count: 14, Support: 0.7\n",
            "('Cheese',) - Count: 8, Support: 0.4\n",
            "('Shampoo',) - Count: 10, Support: 0.5\n",
            "('Bread',) - Count: 13, Support: 0.65\n",
            "('Milk',) - Count: 9, Support: 0.45\n",
            "... (more frequent itemsets found)\n",
            "\n",
            "Total Association Rules Generated:  130\n",
            "Sample Rules:\n",
            "('Towel',) => ('Eggs', 'Juice'), Support: 0.35, Confidence: 0.6364\n",
            "('Towel',) => ('Juice', 'Cereal'), Support: 0.35, Confidence: 0.6364\n",
            "('Juice',) => ('Eggs',), Support: 0.45, Confidence: 0.6429\n",
            "('Diapers',) => ('Juice',), Support: 0.45, Confidence: 0.6429\n",
            "('Juice',) => ('Diapers',), Support: 0.45, Confidence: 0.6429\n",
            "... (more rules found)\n",
            "\n",
            "--- BRUTE-FORCE RESULTS ---\n",
            "Total Frequent Itemsets Found: 66\n",
            "Frequent Itemsets:\n",
            "('Milk',) - Count: 9, Support: 0.45\n",
            "('Bread',) - Count: 13, Support: 0.65\n",
            "('Eggs',) - Count: 12, Support: 0.6\n",
            "('Diapers',) - Count: 14, Support: 0.7\n",
            "('Soap',) - Count: 8, Support: 0.4\n",
            "('Shampoo',) - Count: 10, Support: 0.5\n",
            "('Towel',) - Count: 11, Support: 0.55\n",
            "('Juice',) - Count: 14, Support: 0.7\n",
            "('Cereal',) - Count: 15, Support: 0.75\n",
            "('Cheese',) - Count: 8, Support: 0.4\n",
            "... (more frequent itemsets found)\n",
            "\n",
            "Total Association Rules Generated:  149\n",
            "Sample Rules:\n",
            "['Milk'] => ['Bread'], Support: 0.35, Confidence: 0.7778\n",
            "['Milk'] => ['Juice'], Support: 0.35, Confidence: 0.7778\n",
            "['Milk'] => ['Cereal'], Support: 0.35, Confidence: 0.7778\n",
            "['Bread'] => ['Eggs'], Support: 0.45, Confidence: 0.6923\n",
            "['Eggs'] => ['Bread'], Support: 0.45, Confidence: 0.75\n",
            "... (more rules found)\n",
            "\n",
            "--- EXECUTION TIME COMPARISON ---\n",
            "Apriori execution time: 0.0043 seconds\n",
            "Brute-force execution time: 0.0130 seconds\n",
            "Apriori algorithm is faster.\n",
            "\n",
            "--- FINAL COMPARISON SUMMARY ---\n",
            "Total Frequent Itemsets: Apriori = 66, Brute-force = 66\n",
            "Total Association Rules: Apriori = 130, Brute-force = 149\n",
            "Execution Time: Apriori = 0.0043s, Brute-force = 0.0130s\n"
          ]
        }
      ]
    }
  ]
}